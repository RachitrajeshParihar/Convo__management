{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZo+AzLwr/SI61j2XLkcjx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RachitrajeshParihar/Convo__management/blob/main/convo_management_groq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conversation Management & Classification using Groq API\n",
        "This notebook demonstrates two primary tasks using the Groq API (OpenAI-compatible interface):\n",
        "\n",
        "1. Conversation Management (Truncation & Summarization):\n",
        "Manage long chat histories by truncating them by turns, characters, or words.\n",
        "Implement periodic summarization every k runs, replacing history with a summary.\n",
        "\n",
        "\n",
        "2. Conversation Classification with JSON Schema & Function Calling:\n",
        "Use structured extraction (OpenAI-compatible function-calling) to classify chats and extract user details into a strict JSON Schema.\n",
        "Validate results using jsonschema.\n",
        "\n",
        "\n",
        "##Constraints:\n",
        "No frameworks (Streamlit, Flask, etc.) — only standard Python + requests or OpenAI-compatible SDK.\n",
        "Demonstrations are copy-paste runnable in Colab (API keys placeholder).\n",
        "Includes tests and clear printed outputs at each stage."
      ],
      "metadata": {
        "id": "EFQcfU_-6LZp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ghOCgSg2M6n"
      },
      "outputs": [],
      "source": [
        "# ---------- STEP 1: Install required packages and dependencies----------\n",
        "\n",
        "!pip install openai requests jsonschema -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- STEP 2: Configure API & Import Libraries ----------\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# ============= CONFIG =============\n",
        "# Always use the official Groq OpenAI-compatible API base\n",
        "GROQ_API_BASE = \"https://api.groq.com/openai/v1\"\n",
        "\n",
        "# Use a valid Groq-hosted model\n",
        "GROQ_MODEL = \"moonshotai/kimi-k2-instruct\"   # ✅ Default recommendation\n",
        "\n",
        "# Ask for API key securely\n",
        "if \"GROQ_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass(\"Enter your Groq API key: \")\n",
        "\n",
        "GROQ_API_KEY = os.environ[\"GROQ_API_KEY\"]\n",
        "\n",
        "print(\"[INFO] Configured API settings. Base:\", GROQ_API_BASE, \"Model:\", GROQ_MODEL)"
      ],
      "metadata": {
        "id": "G0cnwLhT2PfG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b816731a-f794-4f2a-e06b-eaee82316fcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Configured API settings. Base: https://api.groq.com/openai/v1 Model: moonshotai/kimi-k2-instruct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- STEP 3: OpenAI Client (Groq-Compatible) ----------\n",
        "from openai import OpenAI\n",
        "import requests\n",
        "\n",
        "# Configure OpenAI client with Groq base\n",
        "client = OpenAI(\n",
        "    api_key=os.environ[\"GROQ_API_KEY\"],\n",
        "    base_url=GROQ_API_BASE\n",
        ")\n",
        "\n",
        "# requests fallback\n",
        "def groq_request_fallback(prompt, model=GROQ_MODEL):\n",
        "    url = f\"{GROQ_API_BASE}/chat/completions\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {os.environ['GROQ_API_KEY']}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    data = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "    }\n",
        "    response = requests.post(url, headers=headers, json=data)\n",
        "    return response.json()\n",
        "\n",
        "print(\"[INFO] OpenAI/Groq client initialized using model:\", GROQ_MODEL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTYm8-PsmuW8",
        "outputId": "d3d33aac-4ab4-45be-f135-68b64a098fbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] OpenAI/Groq client initialized using model: moonshotai/kimi-k2-instruct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- STEP 4: Conversation Management Implementation ----------\n",
        "# Functions for Task 1\n",
        "def truncate_by_turns(history, n):\n",
        "    return history[-n:]\n",
        "\n",
        "def truncate_by_chars(history, max_chars):\n",
        "    truncated, total = [], 0\n",
        "    for msg in reversed(history):\n",
        "        ml = len(msg[\"content\"])\n",
        "        if total + ml <= max_chars:\n",
        "            truncated.insert(0, msg)\n",
        "            total += ml\n",
        "        else:\n",
        "            break\n",
        "    return truncated\n",
        "\n",
        "def truncate_by_words(history, max_words):\n",
        "    truncated, total = [], 0\n",
        "    for msg in reversed(history):\n",
        "        wl = len(msg[\"content\"].split())\n",
        "        if total + wl <= max_words:\n",
        "            truncated.insert(0, msg)\n",
        "            total += wl\n",
        "        else:\n",
        "            break\n",
        "    return truncated\n",
        "\n",
        "def summarize_with_model(text, model, client_or_requests=\"client\"):\n",
        "    if client_or_requests == \"client\":\n",
        "        resp = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[{\"role\": \"user\", \"content\": f\"Summarize: {text}\"}]\n",
        "        )\n",
        "        return resp.choices[0].message.content.strip()\n",
        "    else:\n",
        "        resp = groq_request_fallback(f\"Summarize: {text}\", model=model)\n",
        "        return resp[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "\n",
        "def periodic_summarize(history, run_count, k, summarizer_fn):\n",
        "    if run_count % k == 0:\n",
        "        text = \"\\n\".join([f\"{m['role']}: {m['content']}\" for m in history])\n",
        "        summary = summarizer_fn(text)\n",
        "        return [{\"role\": \"system\", \"content\": f\"[Summary {run_count}] {summary}\"}]\n",
        "    return history\n",
        "\n",
        "print(\"[INFO] Conversation management functions defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0s9fLS9muQp",
        "outputId": "4df433aa-f11f-4262-ba84-49ffd7ed8458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Conversation management functions defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- STEP 5: Demo Truncation ----------\n",
        "sample_history = [\n",
        "    {\"role\": \"user\", \"content\": \"Hello, my name is Alice.\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Hi Alice, how can I help you today?\"},\n",
        "    {\"role\": \"user\", \"content\": \"I’d like to book a flight to Paris.\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"What dates are you considering?\"},\n",
        "    {\"role\": \"user\", \"content\": \"Next week, preferably Monday.\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Got it. One ticket from NYC to Paris next Monday.\"}\n",
        "]\n",
        "\n",
        "print(\"Last 2 turns:\", truncate_by_turns(sample_history, 2))\n",
        "print(\"\\nLimit 200 chars:\", truncate_by_chars(sample_history, 200))\n",
        "print(\"\\nLimit 50 words:\", truncate_by_words(sample_history, 50))\n",
        "\n",
        "assert len(truncate_by_turns(sample_history, 2)) == 2\n",
        "print(\"[TEST] Truncate by turns passed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsgdTkZtmuM_",
        "outputId": "c1cdd9d9-b601-4a18-e85f-671caca92ca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last 2 turns: [{'role': 'user', 'content': 'Next week, preferably Monday.'}, {'role': 'assistant', 'content': 'Got it. One ticket from NYC to Paris next Monday.'}]\n",
            "\n",
            "Limit 200 chars: [{'role': 'assistant', 'content': 'Hi Alice, how can I help you today?'}, {'role': 'user', 'content': 'I’d like to book a flight to Paris.'}, {'role': 'assistant', 'content': 'What dates are you considering?'}, {'role': 'user', 'content': 'Next week, preferably Monday.'}, {'role': 'assistant', 'content': 'Got it. One ticket from NYC to Paris next Monday.'}]\n",
            "\n",
            "Limit 50 words: [{'role': 'user', 'content': 'Hello, my name is Alice.'}, {'role': 'assistant', 'content': 'Hi Alice, how can I help you today?'}, {'role': 'user', 'content': 'I’d like to book a flight to Paris.'}, {'role': 'assistant', 'content': 'What dates are you considering?'}, {'role': 'user', 'content': 'Next week, preferably Monday.'}, {'role': 'assistant', 'content': 'Got it. One ticket from NYC to Paris next Monday.'}]\n",
            "[TEST] Truncate by turns passed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- STEP 6: Periodic Summarization Demo ----------\n",
        "history = [\n",
        "    {\"role\": \"user\", \"content\": \"Hello\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Hi!\"},\n",
        "    {\"role\": \"user\", \"content\": \"Book a flight?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"When?\"},\n",
        "]\n",
        "\n",
        "for run in range(1, 7):\n",
        "    history = periodic_summarize(history, run, 3,\n",
        "                                 lambda t: f\"(Simulated summary of {len(t)} chars)\")\n",
        "    print(f\"\\nRun {run} -> history:\")\n",
        "    for msg in history:\n",
        "        print(msg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyLa7q5zmuGK",
        "outputId": "795a2f78-a1fb-41a4-9274-d1161412bcc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Run 1 -> history:\n",
            "{'role': 'user', 'content': 'Hello'}\n",
            "{'role': 'assistant', 'content': 'Hi!'}\n",
            "{'role': 'user', 'content': 'Book a flight?'}\n",
            "{'role': 'assistant', 'content': 'When?'}\n",
            "\n",
            "Run 2 -> history:\n",
            "{'role': 'user', 'content': 'Hello'}\n",
            "{'role': 'assistant', 'content': 'Hi!'}\n",
            "{'role': 'user', 'content': 'Book a flight?'}\n",
            "{'role': 'assistant', 'content': 'When?'}\n",
            "\n",
            "Run 3 -> history:\n",
            "{'role': 'system', 'content': '[Summary 3] (Simulated summary of 64 chars)'}\n",
            "\n",
            "Run 4 -> history:\n",
            "{'role': 'system', 'content': '[Summary 3] (Simulated summary of 64 chars)'}\n",
            "\n",
            "Run 5 -> history:\n",
            "{'role': 'system', 'content': '[Summary 3] (Simulated summary of 64 chars)'}\n",
            "\n",
            "Run 6 -> history:\n",
            "{'role': 'system', 'content': '[Summary 6] (Simulated summary of 51 chars)'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- STEP 7: Task 2 JSON Schema & Extraction ----------\n",
        "import jsonschema, json\n",
        "\n",
        "user_schema = {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "        \"name\": {\"type\": \"string\"},\n",
        "        \"email\": {\"type\": \"string\", \"format\": \"email\"},\n",
        "        \"phone\": {\"type\": \"string\", \"pattern\": \"^[0-9+() -]{7,20}$\"},\n",
        "        \"location\": {\"type\": \"string\"},\n",
        "        \"age\": {\"type\": \"integer\", \"minimum\": 0, \"maximum\": 130}\n",
        "    },\n",
        "    \"required\": [\"name\", \"email\", \"phone\", \"location\"],\n",
        "    \"additionalProperties\": False\n",
        "}\n",
        "\n",
        "def validate_with_jsonschema(obj, schema=user_schema):\n",
        "    try:\n",
        "        jsonschema.validate(obj, schema)\n",
        "        return True, \"\"\n",
        "    except jsonschema.exceptions.ValidationError as e:\n",
        "        return False, str(e)\n",
        "\n",
        "def call_extraction_function(chat_text, schema, model=GROQ_MODEL, client_or_requests=\"client\"):\n",
        "    instr = f\"Extract fields (name, email, phone, location, age) in JSON {json.dumps(schema)}. Chat: {chat_text}\"\n",
        "    if client_or_requests == \"client\":\n",
        "        resp = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[{\"role\": \"user\", \"content\": instr}],\n",
        "            response_format={\"type\": \"json_object\"}\n",
        "        )\n",
        "        raw = resp.choices[0].message.content\n",
        "    else:\n",
        "        resp = groq_request_fallback(instr, model=model)\n",
        "        raw = resp[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "    try:\n",
        "        parsed = json.loads(raw)\n",
        "        return parsed, None\n",
        "    except Exception as e:\n",
        "        return None, str(e)\n",
        "\n",
        "print(\"[INFO] JSON schema + extraction functions loaded (using model:\", GROQ_MODEL, \")\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y110m-e2mt_J",
        "outputId": "406a104b-9d02-4224-8114-ba551644ab38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] JSON schema + extraction functions loaded (using model: moonshotai/kimi-k2-instruct )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- STEP 8: Demo Extraction ----------\n",
        "sample_chats = [\n",
        "    \"Hello, I'm John Doe. My email is john@example.com, I live in Berlin, I'm 29 years old, call me at +49123456789.\",\n",
        "    \"Hi, Sarah Smith here. Location: Toronto. My contact is sarah.smith@mail.com, phone 416-555-0123. Age 35.\",\n",
        "    \"Name: Peter Johnson. Email: peter.j@example.org. Location: New York. Mobile: (212) 555-9087.\"\n",
        "]\n",
        "\n",
        "for i, chat in enumerate(sample_chats, 1):\n",
        "    print(f\"\\n--- Chat {i} ---\")\n",
        "    parsed, err = call_extraction_function(chat, user_schema)\n",
        "    if err:\n",
        "        print(\"Error parsing:\", err)\n",
        "    else:\n",
        "        print(\"Extracted:\", parsed)\n",
        "        valid, errmsg = validate_with_jsonschema(parsed)\n",
        "        print(\"Validation:\", \"PASSED \" if valid else f\"FAILED  {errmsg}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgyCoMyLmt2b",
        "outputId": "9701542d-f35b-4300-bfa8-6bd51245f6f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Chat 1 ---\n",
            "Extracted: {'name': 'John Doe', 'email': 'john@example.com', 'phone': '+49123456789', 'location': 'Berlin', 'age': 29}\n",
            "Validation: PASSED \n",
            "\n",
            "--- Chat 2 ---\n",
            "Extracted: {'name': 'Sarah Smith', 'email': 'sarah.smith@mail.com', 'phone': '416-555-0123', 'location': 'Toronto', 'age': 35}\n",
            "Validation: PASSED \n",
            "\n",
            "--- Chat 3 ---\n",
            "Extracted: {'name': 'Peter Johnson', 'email': 'peter.j@example.org', 'phone': '(212) 555-9087', 'location': 'New York'}\n",
            "Validation: PASSED \n"
          ]
        }
      ]
    }
  ]
}